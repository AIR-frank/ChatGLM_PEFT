{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "\n",
    "# 定义从文件中读取 JSON 数据的函数\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# 定义将结果写入文件的函数\n",
    "def write_json_file(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# 假设输入文件路径和输出文件路径\n",
    "input_file = 'hotpot_train_v1.1.json'  # 本地 JSON 文件路径\n",
    "output_file = 'train.json'  # 输出文件路径\n",
    "# /home/lpc/repos/HotPotQA/ChatGLM_PEFT/main/data/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list= read_json_file(input_file)\n",
    "\n",
    "for data in data_list:\n",
    "    if 'type' in data:\n",
    "        del data['type']    \n",
    "    if 'level' in data:\n",
    "        del data['level']  \n",
    "    #去除超出index范围的sp \n",
    "    valid_supporting_facts = []\n",
    "    context = data[\"context\"]\n",
    "    # print(context[0][0])\n",
    "    context = {item[0]: item[1] for item in context}\n",
    "    # print(context)\n",
    "    # sp[0] :title 在context中是唯一标识符\n",
    "    for sp in data[\"supporting_facts\"]:\n",
    "        if(sp[1]<len(context[sp[0]])):\n",
    "            valid_supporting_facts.append(sp)\n",
    "    # print(len(valid_supporting_facts))\n",
    "    sp_map = []\n",
    "    for sp in valid_supporting_facts:\n",
    "        if sp[0] not in sp_map:\n",
    "            sp_map.append(sp[0])\n",
    "    data[\"supporting_facts\"] = valid_supporting_facts\n",
    "\n",
    "\n",
    "    # 剪除过多的context段落\n",
    "    lenth = len(sp_map)\n",
    "\n",
    "    # 选取有效和无效 1:1 所以只有<5的context才做剪除\n",
    "\n",
    "    if lenth < 5:\n",
    "        need_num = 0\n",
    "        context = []\n",
    "        for item in data[\"context\"]:\n",
    "            if item[0] in sp_map:\n",
    "                context.append(item)\n",
    "            elif need_num < lenth:\n",
    "                context.append(item)\n",
    "                need_num += 1\n",
    "        random.shuffle(context)\n",
    "        data[\"context\"] = context\n",
    "        #     print(item)\n",
    "        #     if item[0] not in sp_map and remove_num >= 0:\n",
    "        #         # print(item[0])\n",
    "        #         data[\"context\"].remove(item)\n",
    "        #         # print(\"context_len:\"+ str(len(data[\"context\"]))+\"\\n\")\n",
    "        #         remove_num -= 1\n",
    "        #         # print(\"remove_num:\"+ str(remove_num)+\"\\n\")\n",
    "        # print(\"\\n\")\n",
    "        # random.shuffle(data[\"context\"])\n",
    "        # for item in data[\"context\"]:\n",
    "        #     print(item[0])\n",
    "\n",
    "# 把sp中的index换成原句，LLM对数字理解能力不强，难以定位到index\n",
    "for data in data_list:\n",
    "    context = data[\"context\"]\n",
    "    context = {item[0]: item[1] for item in context}\n",
    "    for sp in data[\"supporting_facts\"]:\n",
    "        if(sp[1]<len(context[sp[0]])):\n",
    "            sp[1] = context[sp[0]][sp[1]]\n",
    "        # print(sp[1])\n",
    "        # print(\"\\n\")\n",
    "        # print(result[sp[0]][sp[1]])\n",
    "        # print(\"\\n\")\n",
    "\n",
    "# print(data_list[0][\"context\"][\"Ed Wood (film)\"][1])\n",
    "# context = data[0][\"context\"]\n",
    "# result = {item[0]: item[1] for item in context}\n",
    "# print(result[\"Ed Wood (film)\"][1])\n",
    "# print(data_list[0][\"supporting_facts\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数来处理每个对象并生成所需格式的列表\n",
    "def process_data(data_list):\n",
    "    output = []\n",
    "    \n",
    "    for data in data_list:\n",
    "        fix_object = {\n",
    "            \"conversations\" :[]\n",
    "        }\n",
    "        # 生成问题对象\n",
    "        question_object = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {\n",
    "                \"question\": data[\"question\"],\n",
    "                \"context\": data[\"context\"]\n",
    "            }\n",
    "        }\n",
    "        question_object[\"content\"] = json.dumps(question_object[\"content\"], ensure_ascii=False)\n",
    "        # output.append(question_object)\n",
    "        fix_object[\"conversations\"].append(question_object)\n",
    "        # 生成回答对象\n",
    "        answer_object = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": {\n",
    "                \"answer\": data[\"answer\"],\n",
    "                \"supporting_facts\": data[\"supporting_facts\"]\n",
    "            }\n",
    "        }\n",
    "        answer_object[\"content\"]  = json.dumps(answer_object[\"content\"], ensure_ascii=False)\n",
    "        # output.append(answer_object)\n",
    "        fix_object[\"conversations\"].append(answer_object)\n",
    "        output.append(fix_object)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [{'role': 'user', 'content': '{\"question\": \"Which magazine was started first Arthur\\'s Magazine or First for Women?\", \"context\": [[\"History of Albanian football\", [\"Football in Albania existed before the Albanian Football Federation (FSHF) was created.\", \" This was evidenced by the team\\'s registration at the Balkan Cup tournament during 1929-1931, which started in 1929 (although Albania eventually had pressure from the teams because of competition, competition started first and was strong enough in the duels) .\", \" Albanian National Team was founded on June 6, 1930, but Albania had to wait 16 years to play its first international match and then defeated Yugoslavia in 1946.\", \" In 1932, Albania joined FIFA (during the 12–16 June convention ) And in 1954 she was one of the founding members of UEFA.\"]], [\"Arthur\\'s Magazine\", [\"Arthur\\'s Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\", \" Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.\", \" In May 1846 it was merged into \\\\\"Godey\\'s Lady\\'s Book\\\\\".\"]], [\"First for Women\", [\"First for Women is a woman\\'s magazine published by Bauer Media Group in the USA.\", \" The magazine was started in 1989.\", \" It is based in Englewood Cliffs, New Jersey.\", \" In 2011 the circulation of the magazine was 1,310,696 copies.\"]], [\"Radio City (Indian radio station)\", [\"Radio City is India\\'s first private FM radio station and was started on 3 July 2001.\", \" It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003).\", \" It plays Hindi, English and regional songs.\", \" It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007.\", \" Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features.\", \" The Radio station currently plays a mix of Hindi and Regional music.\", \" Abraham Thomas is the CEO of the company.\"]]]}'}, {'role': 'assistant', 'content': '{\"answer\": \"Arthur\\'s Magazine\", \"supporting_facts\": [[\"Arthur\\'s Magazine\", \"Arthur\\'s Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\"], [\"First for Women\", \"First for Women is a woman\\'s magazine published by Bauer Media Group in the USA.\"]]}'}]}\n"
     ]
    }
   ],
   "source": [
    "output_data = process_data(data_list)\n",
    "\n",
    "print(output_data[0])\n",
    "with jsonlines.open(output_file, 'w') as writer:    \n",
    "    for item in output_data:\n",
    "        writer.write(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果写入到输出文件中\n",
    "# output_data =  json.dumps(output_data, ensure_ascii=False)\n",
    "# write_json_file(output_file, output_data)\n",
    "# with jsonlines.open(output_file, 'w') as writer:\n",
    "#     writer.write(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取输入\n",
    "# input = read_json_file(\"output.json\")\n",
    "# str = json.dumps(input, ensure_ascii=False)\n",
    "# print(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3-6b-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
