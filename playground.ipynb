{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGLM2-6B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前置依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install protobuf transformers==4.30.2 cpm_kernels torch>=2.0 gradio mdtex2html sentencepiece accelerate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/chatglm3-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"model/chatglm3-6b\", trust_remote_code=True).half().cuda()\n",
    "model = model.eval()\n",
    "history_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response, history in model.stream_chat(tokenizer, \"你的任务是什么?\", history=history_):\n",
    "    history_ = history\n",
    "    print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCGPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from CC.predictor.chatglm import GPTPredict\n",
    "\n",
    "predictor = GPTPredict(model_name=\"ChatGLM2-6B\", model_from_pretrained=\"model/chatglm3-6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictor(\"你好?\", history=[])\n",
    "print(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in predictor.predict_stream(\"你的任务是什么?\", history=[]):\n",
    "    sys.stdout.write('\\r' + res['data'])\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./a.txt', encoding='utf-8') as f:\n",
    "    ask_content = f.read()\n",
    "res = predictor(ask_content, history=[])\n",
    "print(res['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGLM_LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer.chatglm_lora import Trainer\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/chatglm3-6b\", trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(\"model/chatglm3-6b\", trust_remote_code=True)\n",
    "trainer = Trainer(tokenizer=tokenizer, config=config, from_pretrained='./model/chatglm3-6b', loader_name='ChatGLM_Chat', data_path='FDEX2', max_length=3600, batch_size=1, task_name='FDEX2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainer(num_epochs=5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chat预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.chatglm_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/chatglm3-6b', resume_path='./save_model/FDRAG/ChatGLM_44136')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred.chat('<rag>检索增强知识: \\n1.《政府采购代理机构管理暂行办法》(财库[2018]2号)\\n第十三条 代理机构受采购人委托办理采购事宜，应当与采购人签订委托代理协议，明确采购代理范围、权限、期限、档案保存、代理费用收取方式及标准、协议解除及终止、违约责任等具体事项，约定双方权利义务。</rag>\\n请根据以上检索增强知识回答以下问题\\n采购人委托采购代理机构代理采购项目，发布招标公告后，有权更换采购代理机构吗?', max_length=3000, history=history)\n",
    "history = result[1]\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预测文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.chatglm_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/chatglm3-6b', resume_path='./save_model/FDLaw/ChatGLM_5755')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred('Instrcution: 请识别该商品的要素: 理光（Ricoh） M2700/M2701/2702多功能黑白激光复合机 a3复合机打印机一体机办公 M 2702(网络+双面+输稿器+7寸触屏) 官方标配\\n Answer:', max_length=512)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./a.txt', encoding='utf-8') as f:\n",
    "    ask_content = f.read()\n",
    "result = pred(ask_content, max_length=512)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGLM_LoRA RAG 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建或者加载chromadb客户端\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "DB_SAVE_DIR = './chroma_data'\n",
    "DB_NAME = 'FDQA'\n",
    "N_RESULTS = 1\n",
    "\n",
    "client = chromadb.PersistentClient(DB_SAVE_DIR)\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"DMetaSoul/sbert-chinese-general-v2\")\n",
    "collection = client.get_or_create_collection(DB_NAME, embedding_function=sentence_transformer_ef, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.chatglm_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/chatglm3-6b', resume_path='./save_model/FDRAG/ChatGLM_44136')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = '采购人委托采购代理机构代理采购项目，发布招标公告后，有权更换采购代理机构吗?'\n",
    "res = collection.query(\n",
    "    query_texts=[user_question],\n",
    "    n_results=N_RESULTS\n",
    ")\n",
    "if len(res['metadatas']) > 0:\n",
    "    clue = res['metadatas'][0][0]['clue']\n",
    "else:\n",
    "    clue = '没有相关知识'\n",
    "rag_user_question = f'<rag>检索增强知识: \\n{clue}</rag>\\n请根据以上检索增强知识回答以下问题\\n{user_question}'\n",
    "result = pred.chat(rag_user_question, history=history)\n",
    "history = result[1]\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qianwen_LoRA\n",
    "\n",
    "运行前请参阅[Qianwen-14B-Chat-Int4](https://huggingface.co/Qwen/Qwen-14B-Chat-Int4)安装相关依赖."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.trainer.qianwen_lora import Trainer\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/Qwen-14B-Chat-Int4\", trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(\"model/Qwen-14B-Chat-Int4\", trust_remote_code=True)\n",
    "config.disable_exllama = True\n",
    "trainer = Trainer(tokenizer=tokenizer, config=config, from_pretrained='./model/Qwen-14B-Chat-Int4', loader_name='Qianwen_Chat', data_path='FD', max_length=512, batch_size=1, task_name='FD_Qianwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainer(num_epochs=5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Accelerator分布式训练加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! accelerate launch run_qianwen_lora.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.qianwen_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/Qwen-14B-Chat-Int4', resume_path='./save_model/FDQALaw_Qianwen/Qwen_39000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred.chat('hello,我想问下中华人民共和国民法典中第三条是什么?')\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预测文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.chatglm_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/chatglm3-6b', resume_path='./save_model/BossCondition/ChatGLM_25108')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred('Instrcution: 请识别该商品的要素: 理光（Ricoh） M2700/M2701/2702多功能黑白激光复合机 a3复合机打印机一体机办公 M 2702(网络+双面+输稿器+7寸触屏) 官方标配\\n Answer:', max_length=512)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('./data/Boss/BertPred/复印机_retrieved.tsv', encoding='utf-8') as f:\n",
    "    ori_list = f.read().split('\\n')\n",
    "\n",
    "if ori_list[-1] == '':\n",
    "    ori_list = ori_list[:-1]\n",
    "\n",
    "result = []\n",
    "iter = tqdm(ori_list)\n",
    "for item in iter:\n",
    "    item = item.split('\\t')\n",
    "    res = pred(f'Instrcution: 请识别该商品的要素: {item[2]}\\n Answer:', max_length=512)\n",
    "    res_item = {\n",
    "        'pred': res\n",
    "    }\n",
    "    answer_index = res.find('Answer:')\n",
    "    iter.set_postfix(pred=json.dumps(res[answer_index + 7:], ensure_ascii=False))\n",
    "    result.append(res_item)\n",
    "\n",
    "with open('./data_record/BertPred_ChatGLMLoRA/复印机.json', 'w', encoding='utf-8') as f:\n",
    "    for item in result:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预测商品蕴涵关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CC.predictor.chatglm_lora import Predictor\n",
    "\n",
    "pred = Predictor(model_from_pretrained='./model/chatglm3-6b', resume_path='./save_model/BossRTE/ChatGLM_22264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred('Instruction: 请判断以下两个商品是否为同款商品\\nContext: Source: 联想(Lenovo）启天 M415-B114 台式计算机 I3-7100/8G/1T/无光驱/15L机箱/21.5寸显示器 5288\\nTarget: 戴尔（DELL） I3-6100 戴尔（DELL）成就3667-R1308商用台式电脑整机（i3-6100 4G 1T WIFI 蓝牙 三年上门 硬盘保留 Win10）19.5英寸 3455\\nAnswer: ', max_length=512)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STS数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('./data/Boss/RTE/dev.json', encoding='utf-8') as f:\n",
    "    ori_list = f.read().split('\\n')\n",
    "\n",
    "if ori_list[-1] == '':\n",
    "    ori_list = ori_list[:-1]\n",
    "\n",
    "iter = tqdm(ori_list)\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for item in iter:\n",
    "    item = json.loads(item)\n",
    "    res = pred(item['context'], max_length=512)\n",
    "    res = res.split('预测结果: ')\n",
    "    if len(res) < 2:\n",
    "        res = 1\n",
    "    else:\n",
    "        res = int(res[1])\n",
    "    gold = int(item['target'].split('预测结果: ')[1])\n",
    "    if res == 1:\n",
    "        if res == gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if res == gold:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "    iter.set_postfix(F1=f1, p=p, r=r)\n",
    "\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全样本环境预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('./data/Boss/BertPred/复印机_retrieved.tsv', encoding='utf-8') as f:\n",
    "    ori_list = f.read().split('\\n')\n",
    "\n",
    "if ori_list[-1] == '':\n",
    "    ori_list = ori_list[:-1]\n",
    "\n",
    "iter = tqdm(ori_list)\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "current_id = 0\n",
    "current_index = 0\n",
    "for idx, item in enumerate(iter):\n",
    "    item = item.split('\\t')\n",
    "    id = item[0]\n",
    "    if id != current_id:\n",
    "        current_id = id\n",
    "        current_index = idx\n",
    "    ori_item = ori_list[current_index]\n",
    "    ori_item = ori_item.split('\\t')\n",
    "    if ori_item[2] == item[2]:\n",
    "        continue\n",
    "    if len(item) < 4:\n",
    "        item.append(1)\n",
    "    if len(ori_item) < 4:\n",
    "        ori_item.append(1)\n",
    "    res = pred(f\"Instruction: 请判断以下两个商品是否为同款商品\\nContext: Source: {ori_item[2]} {ori_item[3]}\\nTarget: {item[2]} {item[3]}\\nAnswer: \", max_length=512)\n",
    "    res = res.split('预测结果: ')\n",
    "    if len(res) < 2:\n",
    "        res = 1\n",
    "    else:\n",
    "        res = int(res[1])\n",
    "    gold = int(item[5]) if len(item) > 5 else 1\n",
    "    if res == 1:\n",
    "        if res == gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if res == gold:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    p = 0 if tp + fp == 0 else tp / (tp + fp)\n",
    "    r = 0 if tp + fn == 0 else tp / (tp + fn)\n",
    "    f1 = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
    "    iter.set_postfix(F1=f1, p=p, r=r)\n",
    "\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_ = tp + 988 / 2\n",
    "fp_ = fp + 52 / 2\n",
    "p = tp_ / (tp_ + fp_)\n",
    "r = tp_ / (tp_ + fn)\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print(f'F1: {f1}, P: {p}, R: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用ChatGLM3-6B对商品进行要素抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from CC.predictor.chatglm import GPTPredict\n",
    "\n",
    "predictor = GPTPredict(model_name=\"ChatGLM2-6B\", model_from_pretrained=\"model/chatglm3-6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('./data/Boss/train.json') as f:\n",
    "    ori_data = f.read().split('\\n')\n",
    "\n",
    "if ori_data[-1] == '':\n",
    "    ori_data.pop()\n",
    "\n",
    "result = []\n",
    "for item in tqdm(ori_data):\n",
    "    data = json.loads(item)\n",
    "    item_id = data['item_id']\n",
    "    context = data['context']\n",
    "    question = context.replace('\\n Answer: ', '')\n",
    "    res = predictor.generate(question, max_length=1024)\n",
    "    result.append({'item_id': item_id, 'question': question, 'answer': res})\n",
    "\n",
    "with open('./data/Boss/train_result.json', encoding='utf-8', mode='w') as f:\n",
    "    for item in result:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用ChatGLM3-6B预测商品蕴涵关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from CC.predictor.chatglm import GPTPredict\n",
    "\n",
    "predictor = GPTPredict(model_name=\"ChatGLM2-6B\", model_from_pretrained=\"model/chatglm3-6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('./data/Boss/BertPred/台式计算机.tsv', encoding='utf-8') as f:\n",
    "    ori_list = f.read().split('\\n')\n",
    "\n",
    "if ori_list[-1] == '':\n",
    "    ori_list = ori_list[:-1]\n",
    "\n",
    "iter = tqdm(ori_list)\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "current_id = 0\n",
    "current_index = 0\n",
    "for idx, item in enumerate(iter):\n",
    "    item = item.split('\\t')\n",
    "    id = item[0]\n",
    "    if id != current_id:\n",
    "        current_id = id\n",
    "        current_index = idx\n",
    "    ori_item = ori_list[current_index]\n",
    "    ori_item = ori_item.split('\\t')\n",
    "    if ori_item[2] == item[2]:\n",
    "        continue\n",
    "    res = predictor.generate(f\"请判断以下两个商品是否为同款商品，直接回答“同款”或“非同款”即可。\\n文本1： {ori_item[2]} {ori_item[3]}\\n文本2： {item[2]} {item[3]}\\n回答：\", max_length=1024)\n",
    "    if '非同款' in res:\n",
    "        res = 0\n",
    "    else:\n",
    "        res = 1\n",
    "    gold = int(item[5]) if len(item) > 5 else 1\n",
    "    if res == 1:\n",
    "        if res == gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if res == gold:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    p = 0 if tp + fp == 0 else tp / (tp + fp)\n",
    "    r = 0 if tp + fn == 0 else tp / (tp + fn)\n",
    "    f1 = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
    "    iter.set_postfix(F1=f1, p=p, r=r)\n",
    "\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_ = tp + 988 / 2\n",
    "fp_ = fp + 52 / 2\n",
    "p = tp_ / (tp_ + fp_)\n",
    "r = tp_ / (tp_ + fn)\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print(f'F1: {f1}, P: {p}, R: {r}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcpower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
