{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "import string\n",
    "\n",
    "# 定义从文件中读取 JSON 数据的函数\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# 定义将结果写入文件的函数\n",
    "def write_json_file(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# 假设输入文件路径和输出文件路径\n",
    "input_file = './data/hotpot_train_v1.1.json'  # 本地 JSON 文件路径\n",
    "output_file = './data/train.json'  # 输出文件路径\n",
    "# /home/lpc/repos/HotPotQA/ChatGLM_PEFT/main/data/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list= read_json_file(input_file)\n",
    "\n",
    "for data in data_list:\n",
    "    if 'type' in data:\n",
    "        del data['type']    \n",
    "    if 'level' in data:\n",
    "        del data['level']  \n",
    "\n",
    "    #\n",
    "    # 处理sp中的异常index\n",
    "    #   \n",
    "   \n",
    "    valid_supporting_facts = []\n",
    "    context = data[\"context\"]\n",
    "    # print(context[0][0])\n",
    "    context = {item[0]: item[1] for item in context}\n",
    "    # sp[0] :title 在context中是唯一标识符\n",
    "    for sp in data[\"supporting_facts\"]:\n",
    "        if(sp[1]<len(context[sp[0]])):\n",
    "            # print(sp[0])\n",
    "            # print(context[sp[0]])\n",
    "            valid_supporting_facts.append(sp)\n",
    "    # print(len(valid_supporting_facts))\n",
    "    sp_map = []\n",
    "    for sp in valid_supporting_facts:\n",
    "        if sp[0] not in sp_map:\n",
    "            sp_map.append(sp[0])\n",
    "    data[\"supporting_facts\"] = valid_supporting_facts\n",
    "\n",
    "\n",
    "    #\n",
    "    # 剪除过多的context段落\n",
    "    #  \n",
    "\n",
    "    lenth = len(sp_map)\n",
    "    # 选取有效和无效 1:1 所以只有<5的context才做剪除\n",
    "    if lenth < 5:\n",
    "        need_num = 0\n",
    "        context = []\n",
    "        for item in data[\"context\"]:\n",
    "            if item[0] in sp_map:\n",
    "                context.append(item)\n",
    "            elif need_num < lenth:\n",
    "                context.append(item)\n",
    "                need_num += 1\n",
    "        random.shuffle(context)\n",
    "        data[\"context\"] = context\n",
    "        # print(data[\"context\"])\n",
    "# print(data_list)\n",
    "    #\n",
    "    # remove(item) bug\n",
    "    #  （弃用）\n",
    "\n",
    "    # print(data[\"context\"])\n",
    "        #     print(item)\n",
    "        #     if item[0] not in sp_map and remove_num >= 0:\n",
    "        #         # print(item[0])\n",
    "        #         data[\"context\"].remove(item)\n",
    "        #         # print(\"context_len:\"+ str(len(data[\"context\"]))+\"\\n\")\n",
    "        #         remove_num -= 1\n",
    "        #         # print(\"remove_num:\"+ str(remove_num)+\"\\n\")\n",
    "        # print(\"\\n\")\n",
    "        # random.shuffle(data[\"context\"])\n",
    "        # for item in data[\"context\"]:\n",
    "        #     print(item[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  把sp中的index换成原句，LLM对数字理解能力不强，难以定位到index\n",
    "#  （为进一步压缩长度，并且提高预测结果，该方案已弃用）\n",
    "\n",
    "# for data in data_list:\n",
    "#     context = data[\"context\"]\n",
    "#     context = {item[0]: item[1] for item in context}\n",
    "#     for sp in data[\"supporting_facts\"]:\n",
    "#         if(sp[1]<len(context[sp[0]])):\n",
    "#             sp[1] = context[sp[0]][sp[1]]\n",
    "\n",
    "# print(data_list[0][\"context\"][\"Ed Wood (film)\"][1])\n",
    "# context = data[0][\"context\"]\n",
    "# result = {item[0]: item[1] for item in context}\n",
    "# print(result[\"Ed Wood (film)\"][1])\n",
    "# print(data_list[0][\"supporting_facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 把context中的句子标上ABCD......XYZ\n",
    "#\n",
    "\n",
    "#\n",
    "# 评估长度\n",
    "#\n",
    "\n",
    "# count = 0\n",
    "# _sum = 0\n",
    "# _max = -1\n",
    "# out_26_count = 0\n",
    "# out_52_count = 0\n",
    "# for data in data_list:\n",
    "#     sub = 0\n",
    "#     for item in data['context']:\n",
    "#         sub += len(item[1])\n",
    "#     if sub > _max :\n",
    "#         _max = sub\n",
    "#     if sub > 26 :\n",
    "#         out_26_count += 1\n",
    "#     if sub > 52 :\n",
    "#         out_52_count += 1\n",
    "#     _sum += sub\n",
    "#     count += 1\n",
    "\n",
    "# print(f\"总context句子数:{count}\")\n",
    "# print(f\"每条数据平均contxet句子数:{_sum/count}\")\n",
    "# print(f\"一条数据最多context句子数:{_max}\")\n",
    "# print(f\"超出26条的条数:{out_26_count}\")\n",
    "# print(f\"超出26条的占比:{out_26_count/count}\")\n",
    "# print(f\"超出52条的条数:{out_52_count}\")\n",
    "# print(f\"超出52条的占比:{out_52_count/count}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 把context中的句子标上ABCD......XYZ\n",
    "# \n",
    "#print(data_list)\n",
    "\n",
    "LETTERS = list(string.ascii_uppercase)#字母表\n",
    "# print(LETTERS[0])\n",
    "for data in data_list:\n",
    "    context = data['context']\n",
    "    new_context = []\n",
    "    count = 0\n",
    "    for item in context:\n",
    "        paragragh = item[1]\n",
    "        new_para = []\n",
    "        for sent in paragragh:\n",
    "            letter_index = count % 26\n",
    "            letter = LETTERS[letter_index] \n",
    "            letter_suffix = int(count/26)\n",
    "            key = letter + str(letter_suffix)\n",
    "            new_sent_dict = {key:sent}\n",
    "            new_para.append(new_sent_dict)\n",
    "            count += 1 \n",
    "        item[1] = new_para       \n",
    "        new_context.append(item)\n",
    "    data['context'] = new_context\n",
    "    # print(data['context'])      \n",
    "        # print(item[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 把sp中的index替换为对应的ABCD标号\n",
    "# \n",
    "for data in data_list:\n",
    "    sp_list = data['supporting_facts']\n",
    "    context = {item[0]: item[1] for item in data['context']}\n",
    "    # print(context)\n",
    "    new_sp_list = []\n",
    "    for sp in sp_list:\n",
    "        title = sp[0]\n",
    "        sent_index = sp[1]\n",
    "        # print(list(context[title][sent_index].keys())[0])\n",
    "        sp[1] = list(context[title][sent_index].keys())[0]\n",
    "    # print(data['supporting_facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 拆解为两个任务\n",
    "# 任务1：回答sp,只需要title和ABCD标号\n",
    "# 任务2：回答answer\n",
    "# \n",
    "output = []\n",
    "for data in data_list:\n",
    "    fix_object_1 = {\n",
    "        \"conversations\" :[]\n",
    "    }\n",
    "    fix_object_2 = {\n",
    "        \"conversations\" :[]\n",
    "    }\n",
    "    # 任务1a\n",
    "    question_object_1 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": {\n",
    "            \"指令：请你根据context回答question,回答必须简短明晰。输入如下:\"\n",
    "            \"question\": data[\"question\"],\n",
    "            \"context\": data[\"context\"]\n",
    "        }\n",
    "    }\n",
    "    question_object_1[\"content\"] = json.dumps(question_object_1[\"content\"], ensure_ascii=False)\n",
    "    answer_object_1 = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": data[\"answer\"] \n",
    "    }\n",
    "    answer_object_1[\"content\"] = json.dumps(answer_object_1[\"content\"], ensure_ascii=False)\n",
    "    # print(type(answer_object_1['content']))\n",
    "    fix_object_1[\"conversations\"].append(question_object_1)\n",
    "    fix_object_1[\"conversations\"].append(answer_object_1)\n",
    "    output.append(fix_object_1)\n",
    "    # 任务2\n",
    "    question_object_2 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": {\n",
    "            \"指令：请你根据question和answer在context中寻找支持答案的语句,其中context中有多个item，每个item是由一个tiele(item的唯一表示)和一个语句列表组成的，每条语句前有语句标号如A0,B1(标号作为语句的唯一标识符)。你的回答必须按照以下给出的json格式的数组进行返回[[title,语句标号],[title,语句标号],.....]注意如果由多个语句支持答案，你需要找出最相关的几句话，title和语句标号必须与你找的item和语句的标号完全一致，方便我定位。输入如下:\"\n",
    "            \"question\":data[\"question\"],\n",
    "            \"answer\":data[\"answer\"],\n",
    "            \"context\":data[\"context\"]\n",
    "        }\n",
    "    }\n",
    "    question_object_2[\"content\"] = json.dumps(question_object_2[\"content\"], ensure_ascii=False)\n",
    "    answer_object_2 = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\":data['supporting_facts']\n",
    "    }\n",
    "    answer_object_2[\"content\"] = json.dumps(answer_object_2[\"content\"], ensure_ascii=False)\n",
    "    fix_object_2[\"conversations\"].append(question_object_2)\n",
    "    fix_object_2[\"conversations\"].append(answer_object_2)\n",
    "    output.append(fix_object_2)\n",
    "# print(output)\n",
    "# output = json.dumps(output, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output)1\n",
    "with jsonlines.open(output_file, 'w') as writer:    \n",
    "    for item in output:\n",
    "        # print(item)\n",
    "        writer.write(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果写入到输出文件中\n",
    "# output_data =  json.dumps(output_data, ensure_ascii=False)\n",
    "# write_json_file(output_file, output_data)\n",
    "# with jsonlines.open(output_file, 'w') as writer:\n",
    "#     writer.write(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取输入\n",
    "# input = read_json_file(\"output.json\")\n",
    "# str = json.dumps(input, ensure_ascii=False)\n",
    "# print(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3",
   "language": "python",
   "name": "chatglm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
